{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender                        0\n",
      "Age                           0\n",
      "Occupation                    0\n",
      "City_Category                 0\n",
      "Stay_In_Current_City_Years    0\n",
      "Marital_Status                0\n",
      "Product_Category_1            0\n",
      "Product_Category_2            0\n",
      "Product_Category_3            0\n",
      "Purchase                      0\n",
      "dtype: int64\n",
      "(783667, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "df = pd.concat([df_train, df_test])\n",
    "\n",
    "df.drop(columns=['User_ID', 'Product_ID'], inplace=True)\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "print(df.isna().sum())\n",
    "\n",
    "df.drop(columns=['Stay_In_Current_City_Years', 'Marital_Status'], inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550068\n",
      "(550068,)\n",
      "(783667, 7)\n"
     ]
    }
   ],
   "source": [
    "train_length = len(df_train)\n",
    "print(train_length)\n",
    "\n",
    "real_y = df['Purchase']\n",
    "real_y = np.array(real_y)\n",
    "real_y = real_y[0:train_length]\n",
    "print(real_y.shape)\n",
    "\n",
    "df.drop(columns=['Purchase'], inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(783667, 87)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "column_trans = make_column_transformer((OneHotEncoder(), ['Age','Gender','Occupation','City_Category','Product_Category_1','Product_Category_2','Product_Category_3']), remainder='passthrough')\n",
    "real_x = column_trans.fit_transform(df)\n",
    "\n",
    "print(real_x.shape)\n",
    "\n",
    "real_x = real_x.toarray()\n",
    "\n",
    "print(real_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1779729 ]\n",
      " [ 1.1817558 ]\n",
      " [-1.56119326]\n",
      " ...\n",
      " [-1.81701338]\n",
      " [-1.77162273]\n",
      " [-1.7467375 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "real_y = real_y.reshape(-1,1)\n",
    "real_y = sc.fit_transform(real_y)\n",
    "print(real_y)\n",
    "\n",
    "test_x = real_x[train_length:,:]\n",
    "real_x = real_x[0:train_length,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, cv_x, train_y, cv_y = train_test_split(real_x, real_y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "train_y = train_y.reshape(train_y.shape[0],)\n",
    "cv_y = cv_y.reshape(cv_y.shape[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = RandomForestRegressor(n_estimators=3000, max_depth=6, oob_score=True, n_jobs=6, random_state=0, min_samples_split=10, min_samples_leaf=10)\\nmodel.fit(train_x, train_y)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = RandomForestRegressor(n_estimators=3000, max_depth=6, oob_score=True, n_jobs=6, random_state=0, min_samples_split=10, min_samples_leaf=10)\n",
    "model.fit(train_x, train_y)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = ExtraTreesRegressor(n_estimators=3000, \\n                              max_depth=8,\\n                              min_samples_split=10, \\n                              min_samples_leaf=10, \\n                              oob_score=True, \\n                              n_jobs=6, \\n                              random_state=123, \\n                              verbose=1, \\n                              bootstrap=True)\\nmodel.fit(train_x, train_y)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = ExtraTreesRegressor(n_estimators=3000, \n",
    "                              max_depth=8,\n",
    "                              min_samples_split=10, \n",
    "                              min_samples_leaf=10, \n",
    "                              oob_score=True, \n",
    "                              n_jobs=6, \n",
    "                              random_state=123, \n",
    "                              verbose=1, \n",
    "                              bootstrap=True)\n",
    "model.fit(train_x, train_y)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "\n",
    "n_estimators = [100,500,900,1100,1500]\n",
    "max_depth = [2,3,5,10,15]\n",
    "booster = ['gbtree','gblinear']\n",
    "learning_rate = [0.05,0.1,0.15,0.2]\n",
    "min_child_weight = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_grid = {\n",
    "    'n_estimators' : n_estimators,\n",
    "    'max_depth' : max_depth,\n",
    "    'learning_rate' : learning_rate,\n",
    "    'min_child_weight' : min_child_weight,\n",
    "    'booster' : booster\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_cv = RandomizedSearchCV(estimator=model,\n",
    "                          param_distributions=hyperparameter_grid,\n",
    "                          cv=5, n_iter=50,\n",
    "                          scoring='neg_mean_absolute_error', n_jobs=4,\n",
    "                          return_train_score=True,\n",
    "                          verbose=5,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "random_cv.fit(real_x,real_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(cv_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = sc.inverse_transform(pred_y)\n",
    "act_y = sc.inverse_transform(cv_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "error = np.sqrt(mean_squared_error(act_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_y"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_train[\"Purchase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x)\n",
    "predictions = sc.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"sample_submission_V9Inaty.csv\")\n",
    "submit[\"Purchase\"] = predictions\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"Submission_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
